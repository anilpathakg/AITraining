{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppfblZQH71Y",
        "outputId": "4191b057-355c-430c-e476-6df0b8687795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– Reactive Agent (type 'exit' to quit)\n",
            "> hi\n",
            "\n",
            "Hello! How can I assist you today?\n",
            "\n",
            "> pl tell me the weather of delhi\n",
            "\n",
            "I don't have real-time weather data, but you can easily check the current weather in Delhi using a weather website or app. Typically, you can find information on temperature, humidity, precipitation, and forecasts. If you need general information about Delhi's climate, feel free to ask!\n",
            "\n",
            "> pl tell me the capital of india\n",
            "\n",
            "The capital of India is New Delhi.\n",
            "\n",
            "> what question i asked earlier\n",
            "\n",
            "I'm sorry, but I don't have access to previous conversations or questions. How can I assist you today?\n",
            "\n",
            "> exit\n",
            "bye!\n"
          ]
        }
      ],
      "source": [
        "# reactive_agent.py\n",
        "# pip install openai\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "\n",
        "def ask_llm(prompt: str, system: str = \"You are a concise, helpful assistant.\") -> str:\n",
        "    \"\"\"\n",
        "    Reactive call: no history, just current user input -> model -> reply.\n",
        "    \"\"\"\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()\n",
        "\n",
        "def main():\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        print(\"ERROR: Set OPENAI_API_KEY in your environment.\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"ðŸ¤– Reactive Agent (type 'exit' to quit)\")\n",
        "    while True:\n",
        "        try:\n",
        "            user = input(\"> \").strip()\n",
        "        except (EOFError, KeyboardInterrupt):\n",
        "            print(\"\\nbye!\")\n",
        "            break\n",
        "\n",
        "        if not user:\n",
        "            continue\n",
        "        if user.lower() in {\"exit\", \"quit\"}:\n",
        "            print(\"bye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            reply = ask_llm(user)\n",
        "            print(f\"\\n{reply}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"[error] {e}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}