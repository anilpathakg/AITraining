{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilpathakg/AITraining/blob/main/RAG/RAG_BOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGJHdDontwhJ"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ü§ñ GEN AI RAG CHATBOT ‚Äî CLEAN CLASSROOM VERSION\n",
        "# Topic: Demonstrating RAG with 2025 Knowledge\n",
        "# Author: Anil Pathak | GenAI Training Series\n",
        "# ============================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHgjaw5Wt1Wv",
        "outputId": "73433fad-2a2c-4b67-9a89-9c3d3f254d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[H\u001b[2J"
          ]
        }
      ],
      "source": [
        "# ---- STEP 1: Install Dependencies (Quietly) ----\n",
        "!pip install -q -U langchain langchain-community langchain-openai openai faiss-cpu sentence-transformers tiktoken\n",
        "!clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alFKbYHgt4tg"
      },
      "outputs": [],
      "source": [
        "# ---- STEP 2: Suppress Warnings & Logs ----\n",
        "import warnings, logging, os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"langchain\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"openai\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qImS3He3t75a"
      },
      "outputs": [],
      "source": [
        "# ---- STEP 3: Import Libraries ----\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M42Khvjmt-XL"
      },
      "outputs": [],
      "source": [
        "# ---- STEP 4: Securely Load OpenAI Key (Colab Secrets) ----\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HTaZ-P1uAM_"
      },
      "outputs": [],
      "source": [
        "# ---- STEP 5: Initialize GPT Model ----\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8JtXaPFuCjO",
        "outputId": "5bcc50bb-25ba-4a73-95c7-cb56995cd4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò Building RAG knowledge base (2025 updates)...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- STEP 6: Build Knowledge Base (2025 Context) ----\n",
        "print(\"üìò Building RAG knowledge base (2025 updates)...\\n\")\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "custom_texts = [\n",
        "    \"In February 2025, OpenAI launched GPT-4.1, an upgraded multimodal model with faster reasoning and better factual accuracy.\",\n",
        "    \"GPT-4.1 introduced real-time data plugins and advanced function calling for enterprise applications.\",\n",
        "    \"The model supports long-context reasoning and integrates OpenAI‚Äôs memory features for persistent sessions.\",\n",
        "    \"This release advanced agentic AI capabilities, enabling autonomous decision-making in safe enterprise environments.\"\n",
        "]\n",
        "\n",
        "splitter = CharacterTextSplitter(chunk_size=150, chunk_overlap=0)\n",
        "docs = [Document(page_content=t) for t in custom_texts]\n",
        "split_docs = splitter.split_documents(docs)\n",
        "db = FAISS.from_documents(split_docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3CUa1_euIwx",
        "outputId": "9ef6c6c0-9f75-49be-8056-6cf8e69a5878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Knowledge base ready! Chatbot is now live.\n",
            "üí¨ Type 'exit' anytime to end the chat.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- STEP 7: Build Retrieval + Generation Chain ----\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    chain_type=\"stuff\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Knowledge base ready! Chatbot is now live.\")\n",
        "print(\"üí¨ Type 'exit' anytime to end the chat.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmusJS8duPxn",
        "outputId": "a5e50a14-47a4-4cb7-8f3a-a8955be89e66"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÑ Retrieved Context:\n",
            "   1. GPT-4.1 introduced real-time data plugins and advanced function calling\n",
            "for enterprise applications.\n",
            "   2. In February 2025, OpenAI launched GPT-4.1, an upgraded multimodal model\n",
            "with faster reasoning and better factual accuracy.\n",
            "\n",
            "ü§ñ Chatbot: GPT-4.1 introduced real-time data plugins and advanced function calling for\n",
            "enterprise applications. It is an upgraded multimodal model that features faster\n",
            "reasoning and improved factual accuracy compared to its predecessors. \n",
            "\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "   1. In February 2025, OpenAI launched GPT-4.1, an upgraded multimodal model\n",
            "with faster reasoning and better factual accuracy.\n",
            "   2. This release advanced agentic AI capabilities, enabling autonomous\n",
            "decision-making in safe enterprise environments.\n",
            "\n",
            "ü§ñ Chatbot: I don't know. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- STEP 8: Interactive Chatbot Loop ----\n",
        "while True:\n",
        "    query = input(\"üßë‚Äçüéì You: \").strip()\n",
        "    if query.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
        "        print(\"üëã Chatbot: Goodbye! Keep exploring RAG & GenAI.\")\n",
        "        break\n",
        "\n",
        "    # --- Print Retrieved Context Chunks (for students to see) ---\n",
        "    retrieved_docs = db.similarity_search(query, k=2)\n",
        "    print(\"\\nüìÑ Retrieved Context:\")\n",
        "    for i, d in enumerate(retrieved_docs):\n",
        "        print(textwrap.fill(f\"   {i+1}. {d.page_content}\", width=80))\n",
        "\n",
        "    # --- Generate Final Answer ---\n",
        "    response = qa.run(query)\n",
        "    print(\"\\nü§ñ Chatbot:\",textwrap.fill(response, width=80), \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4ZayJYeXFVcfiWLqbEEBu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}